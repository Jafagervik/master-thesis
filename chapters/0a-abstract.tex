\chapter*{Abstract}
Distributed acoustic sensing (DAS) has become a widespread technology over the last decade, but current processing and anomaly detection methods often prioritize accuracy over efficiency. This thesis addresses the challenge of efficiently processing DAS data while maintaining effective anomaly detection capabilities. We investigate parallel processing techniques for large-scale, dense-sampled DAS data and explore the application of compact autoencoders for rapid anomaly detection.

We present two tools: Judas, a package for efficient loading and processing of DAS data, and TinyDAS, a scalable framework for training autoencoders and performing anomaly detection. These tools aim to significantly reduce computational resources and processing time for DAS data handling. We validate these programs using proprietary and open-source datasets, focusing on railroad monitoring and earthquake detection.

Our research demonstrates that memory mapping can substantially reduce memory requirements for DAS data processing. Unlike existing methods that load entire datasets into memory, our technique utilizes distributed binary file splitting and on-demand loading, allowing for efficient handling of large-scale DAS data with minimal memory overhead. Furthermore, we show that half-precision inference on a compact convolutional autoencoder with only 46k parameters can detect anomalies in large matrices with 91\% accuracy in just 5.5ms, while being trained on potentially anomalous data.

This work promotes more efficient techniques for processing DAS data, which can benefit various industries utilizing DAS technology, including infrastructure monitoring and geophysical forecasting. By enhancing data processing pipelines and promoting efficient autoencoder designs, our work at NTNU Centre for Geophysical Forecasting paves the way for more widespread and resource-efficient applications of DAS technology in real-time scenarios.
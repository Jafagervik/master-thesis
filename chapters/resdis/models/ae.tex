\subsection{AE}
\label{resdis:tiny-ae}

The first model to be tested is a traditional dense autoencoder  where we

TODO: Move to appendix??
\begin{table}[hpbt]
    \centering
    \caption{Linear Autoencoder Architecture}
    \begin{tabular}{lrr}
        \toprule
        Layer & Output Shape & Parameters \\
        \midrule
        Input & (1,335,625,) & 0 \\
        Dense (Encoder) & (1024,) & 1,367,680,000 \\
        Dense (Encoder) & (512,) & 524,800 \\
        Dense (Encoder) & (128,) & 65,664 \\
        Dense (Encoder) & (64,) & 8,256 \\
        Dense (Latent) & (32,) & 2,080 \\
        Dense (Decoder) & (64,) & 2,112 \\
        Dense (Decoder) & (128,) & 8,320 \\
        Dense (Decoder) & (512,) & 66,048 \\
        Dense (Decoder) & (1024,) & 525,312 \\
        Dense (Output) & (1,335,625,) & 1,367,680,000 \\
        \midrule
        Total Parameters & & 2,735,562,592 \\
        \bottomrule
    \end{tabular}
    \label{tab:linear_autoencoder}
\end{table}

\textbf{Activation Function:} ReLU (all layers except output)\\
\textbf{Optimizer:} Adam (learning rate: 0.001)